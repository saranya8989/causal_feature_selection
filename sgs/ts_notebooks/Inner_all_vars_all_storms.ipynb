{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95b4e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import netCDF4 as nf\n",
    "from netCDF4 import Dataset\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bf47798",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath=\"/work/FAC/FGSE/IDYST/tbeucler/default/saranya/Data/ECMWF/ERA5_25kmx3hr/\"\n",
    "path=\"/work/FAC/FGSE/IDYST/tbeucler/default/saranya/causal/besttracks/\"\n",
    "output=\"/work/FAC/FGSE/IDYST/tbeucler/default/saranya/causal/create_ts/outputs/\"\n",
    "target=\"/work/FAC/FGSE/IDYST/tbeucler/default/saranya/causal/create_ts/outputs/targets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de0d5c4c-1a90-47e6-8d59-d0a9b0df22a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001_wp_storms.csv  2005_wp_storms.csv\t2009_wp_storms.csv  all\r\n",
      "2002_wp_storms.csv  2006_wp_storms.csv\t2010_wp_storms.csv  nio\r\n",
      "2003_wp_storms.csv  2007_wp_storms.csv\t2020_nh_storms.csv  wp\r\n",
      "2004_wp_storms.csv  2008_wp_storms.csv\t2021_nh_storms.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls /work/FAC/FGSE/IDYST/tbeucler/default/saranya/causal/besttracks/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9500480c-4063-49f4-bd8e-c2573aadc87b",
   "metadata": {},
   "source": [
    "### Read tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4912ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "track = sorted(glob.glob(path+'*2009*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1c2d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracksDF = pd.read_csv(track[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4e73073-155e-46ee-9400-853d5ba84a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['KUJIRA', 'CHAN-HOM', 'LINFA', 'GONI', 'MORAKOT', 'ETAU', 'VAMCO',\n",
       "       'KROVANH', 'DUJUAN', 'CHOI-WAN', 'PARMA', 'MELOR', 'NEPARTAK',\n",
       "       'LUPIT', 'MIRINAE', 'NIDA'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracksDF['name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c32fc-c764-48cf-a222-f4e402ed4e3d",
   "metadata": {},
   "source": [
    "### Extract time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb496656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def largearea_withpres(dataset=None,invar=None,indices=None,tc_irad=None):\n",
    "    ds = xr.Dataset(\n",
    "    data_vars=dict(variable=([\"time\",\"plev\",\"lat\",\"lon\"], invar)),#mysvar[0])),\n",
    "    coords=dict(lat=([\"lat\"], dataset.lat.data),lon=([\"lon\"], dataset.lon.data),time=([\"time\"], np.linspace(0,len(indices)-1,len(indices))),\n",
    "               plev=([\"plev\"],dataset.plev.data)),\n",
    "    attrs=dict(description=\"coords with matrices\"),)\n",
    "    \n",
    "    LATN,LATS,LONE,LONW = tc_irad[0,:]\n",
    "    testsmall = ds['variable'][0,0,:,:].sel(lat=slice(LATS,LATN),lon=slice(LONE,LONW))\n",
    "    if testsmall.shape[0]<testsmall.shape[1]:\n",
    "        rgspt = int(testsmall.shape[0])\n",
    "    else:\n",
    "        rgspt = int(testsmall.shape[1])\n",
    "    rgspt=16\n",
    "    var_out=np.zeros((len(indices),len(dataset.plev.data),rgspt,rgspt))\n",
    "    del testsmall\n",
    "    \n",
    "    for it in range(len(indices)):\n",
    "        latn, lats, lone, lonw = tc_irad[it,:]\n",
    "        for ip in range(len(dm1.plev.data)):\n",
    "            try:\n",
    "                var_out[it,ip,:,:]=ds['variable'][it,ip,:,:].sel(lat=slice(lats,latn),lon=slice(lone,lonw))\n",
    "            except:\n",
    "                var_out[it,ip,:,:]=ds['variable'][it,ip,:,:].sel(lat=slice(lats,latn),lon=slice(lone,lonw))[0:rgspt,0:rgspt]\n",
    "    return var_out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57a82e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########function############\n",
    "def output_indices(TCtrack=None,ERA5date=None,ERA5hour=None):\n",
    "    allindices = []\n",
    "    for timeidx in range(len(TCtrack)):#len(track['time'])):\n",
    "        datetrack,hourtrack = TCtrack['time'][timeidx].split(':')[0],TCtrack['time'][timeidx].split(':')[1][0:2]\n",
    "        ####################################################################################################\n",
    "        # Find the indices in ERA5 data with the same date as track\n",
    "        ####################################################################################################\n",
    "        dateind = []\n",
    "        for ind,obj in enumerate(ERA5date):\n",
    "            if obj==datetrack:\n",
    "                dateind.append(ind)\n",
    "        del ind,obj\n",
    "        hourind = []\n",
    "        hourextract = ERA5hour[int(np.min(np.asarray(dateind))):int(np.max(np.asarray(dateind)))+1]\n",
    "        for ind,obj in enumerate(hourextract):\n",
    "            if obj==hourtrack:            \n",
    "                hourind.append(ind)\n",
    "        allindices.append((int(np.min(np.asarray(dateind))),int(hourind[0])))\n",
    "    return allindices\n",
    "\n",
    "def extract_var(dataset=None,var='var138',indices=None):\n",
    "    extractedvar = []\n",
    "    for i in (range(len(indices))):\n",
    "        realindex = indices[i][0]+indices[i][1]\n",
    "        extractedvar.append(dataset[var][int(realindex),...].data)\n",
    "    return np.asarray(extractedvar)\n",
    "\n",
    "def smallarea(dataset=None,invar=None,indices=None,tc_irad=None):\n",
    "    if len(invar.shape) != 3:\n",
    "        invar = np.squeeze(invar)\n",
    "    ds = xr.Dataset(\n",
    "    data_vars=dict(variable=([\"time\",\"lat\",\"lon\"], invar)),#mysvar[0])),\n",
    "    coords=dict(lat=([\"lat\"], dataset.lat.data),lon=([\"lon\"], dataset.lon.data),time=([\"time\"], np.linspace(0,len(indices)-1,len(indices)))),\n",
    "    attrs=dict(description=\"coords with matrices\"),)\n",
    "    \n",
    "    LATN,LATS,LONE,LONW = tc_irad[0,:]\n",
    "    testsmall = ds['variable'][0,:,:].sel(lat=slice(LATS,LATN),lon=slice(LONE,LONW))\n",
    "    if testsmall.shape[0]<testsmall.shape[1]:\n",
    "        rgspt = int(testsmall.shape[0])\n",
    "    else:\n",
    "        rgspt = int(testsmall.shape[1])\n",
    "    rgspt=16\n",
    "    var_out=np.zeros((len(indices),rgspt,rgspt))\n",
    "    del testsmall\n",
    "    \n",
    "    for it in range(len(indices)):\n",
    "        latn, lats, lone, lonw = tc_irad[it,:]\n",
    "        try:\n",
    "            var_out[it,:,:]=ds['variable'][it,:,:].sel(lat=slice(lats,latn),lon=slice(lone,lonw))\n",
    "        except:\n",
    "            var_out[it,:,:]=ds['variable'][it,:,:].sel(lat=slice(lats,latn),lon=slice(lone,lonw))[0:rgspt,0:rgspt]\n",
    "    return var_out\n",
    "\n",
    "def largearea_withpres(dataset=None,invar=None,indices=None,tc_irad=None):\n",
    "    ds = xr.Dataset(\n",
    "    data_vars=dict(variable=([\"time\",\"plev\",\"lat\",\"lon\"], invar)),#mysvar[0])),\n",
    "    coords=dict(lat=([\"lat\"], dataset.lat.data),lon=([\"lon\"], dataset.lon.data),time=([\"time\"], np.linspace(0,len(indices)-1,len(indices))),\n",
    "               plev=([\"plev\"],dataset.plev.data)),\n",
    "    attrs=dict(description=\"coords with matrices\"),)\n",
    "    \n",
    "    LATN,LATS,LONE,LONW = tc_irad[0,:]\n",
    "    testsmall = ds['variable'][0,0,:,:].sel(lat=slice(LATS,LATN),lon=slice(LONE,LONW))\n",
    "    if testsmall.shape[0]<testsmall.shape[1]:\n",
    "        rgspt = int(testsmall.shape[0])\n",
    "    else:\n",
    "        rgspt = int(testsmall.shape[1])\n",
    "    rgspt=16\n",
    "    var_out=np.zeros((len(indices),len(dataset.plev.data),rgspt,rgspt))\n",
    "    del testsmall\n",
    "    \n",
    "    for it in range(len(indices)):\n",
    "        latn, lats, lone, lonw = tc_irad[it,:]\n",
    "        for ip in range(len(dm1.plev.data)):\n",
    "            try:\n",
    "                var_out[it,ip,:,:]=ds['variable'][it,ip,:,:].sel(lat=slice(lats,latn),lon=slice(lone,lonw))\n",
    "            except:\n",
    "                var_out[it,ip,:,:]=ds['variable'][it,ip,:,:].sel(lat=slice(lats,latn),lon=slice(lone,lonw))[0:rgspt,0:rgspt]\n",
    "    return var_out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cc6c695-6bd5-4f27-8966-b6f4b938c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stormnames = list(tracksDF['name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16c3081d-9960-4b0b-bd10-e75ea0216a82",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2009-04-30',\n",
       " '2009-04-30',\n",
       " '2009-05-01',\n",
       " '2009-05-01',\n",
       " '2009-05-01',\n",
       " '2009-05-01',\n",
       " '2009-05-01',\n",
       " '2009-05-01',\n",
       " '2009-05-01',\n",
       " '2009-05-01',\n",
       " '2009-05-02',\n",
       " '2009-05-02',\n",
       " '2009-05-02',\n",
       " '2009-05-02',\n",
       " '2009-05-02',\n",
       " '2009-05-02',\n",
       " '2009-05-02',\n",
       " '2009-05-02',\n",
       " '2009-05-03',\n",
       " '2009-05-03',\n",
       " '2009-05-03',\n",
       " '2009-05-03',\n",
       " '2009-05-03',\n",
       " '2009-05-03',\n",
       " '2009-05-03',\n",
       " '2009-05-03',\n",
       " '2009-05-04',\n",
       " '2009-05-04',\n",
       " '2009-05-04',\n",
       " '2009-05-04',\n",
       " '2009-05-04',\n",
       " '2009-05-04',\n",
       " '2009-05-04',\n",
       " '2009-05-04',\n",
       " '2009-05-05',\n",
       " '2009-05-05',\n",
       " '2009-05-05',\n",
       " '2009-05-05',\n",
       " '2009-05-05',\n",
       " '2009-05-05',\n",
       " '2009-05-05',\n",
       " '2009-05-05',\n",
       " '2009-05-06',\n",
       " '2009-05-06',\n",
       " '2009-05-06',\n",
       " '2009-05-06',\n",
       " '2009-05-06',\n",
       " '2009-05-06',\n",
       " '2009-05-06',\n",
       " '2009-05-06',\n",
       " '2009-05-07',\n",
       " '2009-05-07',\n",
       " '2009-05-07',\n",
       " '2009-05-07',\n",
       " '2009-05-07',\n",
       " '2009-05-07',\n",
       " '2009-05-07',\n",
       " '2009-05-07',\n",
       " '2009-05-08',\n",
       " '2009-05-08',\n",
       " '2009-05-08',\n",
       " '2009-05-08',\n",
       " '2009-05-08',\n",
       " '2009-05-08',\n",
       " '2009-05-08',\n",
       " '2009-05-08',\n",
       " '2009-05-09',\n",
       " '2009-05-09',\n",
       " '2009-05-09',\n",
       " '2009-05-09',\n",
       " '2009-05-09',\n",
       " '2009-05-09',\n",
       " '2009-05-09',\n",
       " '2009-05-09',\n",
       " '2009-05-10',\n",
       " '2009-05-10',\n",
       " '2009-05-10',\n",
       " '2009-05-10',\n",
       " '2009-05-10',\n",
       " '2009-05-10',\n",
       " '2009-05-10',\n",
       " '2009-05-10',\n",
       " '2009-05-11',\n",
       " '2009-05-11',\n",
       " '2009-05-11',\n",
       " '2009-05-11',\n",
       " '2009-05-11',\n",
       " '2009-05-11',\n",
       " '2009-05-11',\n",
       " '2009-05-11',\n",
       " '2009-05-12',\n",
       " '2009-05-12',\n",
       " '2009-05-12',\n",
       " '2009-05-12',\n",
       " '2009-05-12',\n",
       " '2009-05-12',\n",
       " '2009-05-12',\n",
       " '2009-05-12',\n",
       " '2009-05-13',\n",
       " '2009-05-13',\n",
       " '2009-05-13']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(tracksDF[tracksDF['name']==stormnames[0]].time[i]).split(':')[0] for i in range(len(tracksDF[tracksDF['name']==stormnames[0]].time))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d4fce5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for dm1 files functions\n",
    "def make_timeseries_step1(TCname=None,era5_date=None,era5_hour=None):\n",
    "    track=tracksDF[tracksDF['name']==TCname].reset_index()\n",
    "    lon1=track['lon'].to_numpy()\n",
    "    lat1=track['lat'].to_numpy()\n",
    "    pos = np.stack((lat1, lon1), axis=1)\n",
    "    ###########################################################################\n",
    "    indices_store = output_indices(track,era5_date,era5_hour)\n",
    "    ###########################################################################\n",
    "    tc_irad=np.empty((len(indices_store),4))\n",
    "    tc_irad[:,0] = pos[:,0]-2\n",
    "    tc_irad[:,1] = pos[:,0]+2\n",
    "    tc_irad[:,2] = pos[:,1]-2\n",
    "    tc_irad[:,3] = pos[:,1]+2\n",
    "    return pos,indices_store,tc_irad\n",
    "\n",
    "def make_timeseries_step3(dm1=None,pvarname=None,pvardict=None,indices_store=None):\n",
    "    ts_pdict = {}\n",
    "    for ind,obj in (enumerate(pvarname)):\n",
    "        pvarTS_store = []\n",
    "        for plevv in range(len(dm1.plev.data)):\n",
    "            tempvar = pvardict[pvarname[ind]][:,plevv,...]\n",
    "            tempts = [tempvar[i,...].flatten() for i in range(len(indices_store))]\n",
    "            tempTSERIES = [np.nanmean(obj) for obj in tempts]\n",
    "            pvarTS_store.append(tempTSERIES)\n",
    "        ts_pdict[pvarname[ind]] = np.asarray(pvarTS_store).transpose()\n",
    "    return ts_pdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1324e5bc-c6f1-4b86-9739-25de70e0dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readyear_automatic(year=None):\n",
    "    dm2 = xr.open_dataset(datapath+'/slev_vars/radvars_'+str(year)+'.nc')\n",
    "    #tracklist = sorted(glob.glob('/work/FAC/FGSE/IDYST/tbeucler/default/saranya/causal/besttracks/nio/*_'+str(year)+'*'))\n",
    "    era5_date = [str(dm2.time[i].data).split('T')[0] for i in range(len(dm2.time))]\n",
    "    era5_hour = [str(dm2.time[i].data).split('T')[1][0:2] for i in range(len(dm2.time))]\n",
    "    return dm2,era5_date,era5_hour\n",
    "\n",
    "dm2,era5_date,era5_hour = readyear_automatic(2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2598000-6aed-43d3-9cef-51179517f6cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1557f32010dc4ae0986c3c18fd485001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TCrl_ts = []\n",
    "for TCname in tqdm(stormnames):\n",
    "    ###########################################################################\n",
    "    pos,indices_store,tc_irad = make_timeseries_step1(TCname=TCname,era5_date=era5_date,era5_hour=era5_hour)\n",
    "    ###########################################################################\n",
    "    mysvar = [extract_var(dataset=dm2,var=obj,indices=indices_store) for obj in (list(dm2.keys()))]\n",
    "    ###########################################################################\n",
    "    smallsvarout = [smallarea(dm2,mysvar[i],indices_store,tc_irad) for i in (range(len(mysvar)))]\n",
    "    svarname = ['cape','inst_10m_wnd_gst','inst_moisture_flux','inst_ssh_flux','surfmean_swr_flux','surfmean_lhf',\\\n",
    "           'surfmean_lwr_flux','surfmean_shf','dwnwrdmean_swr_flux','topmean_lwr_flux','topmean_swr_flux',\\\n",
    "           'vimean_moisture_div','surf_lhf','surf_shf','tot_suprcool_liqwtr','tot_wtr_vpr']\n",
    "    svardict = {varnameobj:varobj for (varnameobj,varobj) in zip(svarname,smallsvarout)}\n",
    "    \n",
    "    #############################################################################################\n",
    "\n",
    "    tsdict = {}\n",
    "    for ind,obj in (enumerate(svarname)):\n",
    "        tslist = [svardict[svarname[ind]][i,...].flatten() for i in range(len(indices_store))]\n",
    "        tsdict[svarname[ind]] = [np.nanmean(obj) for obj in tslist]\n",
    "    #############################################################################################\n",
    "    TCrl_ts.append(tsdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32f9b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "storeTCdicts = {}\n",
    "for ind in range(len(TCrl_ts)):\n",
    "    storeTCdicts[stormnames[ind]] = pd.DataFrame.from_dict(TCrl_ts[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "841204da-9880-4dda-b324-1d7353ed7ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind,obj in enumerate(stormnames):\n",
    "    storeTCdicts[obj].to_csv(output+'2009_radvar_wpac_'+str(obj)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b63aa4d2-aa0c-494c-8de4-6fed5437f7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cape</th>\n",
       "      <th>inst_10m_wnd_gst</th>\n",
       "      <th>inst_moisture_flux</th>\n",
       "      <th>inst_ssh_flux</th>\n",
       "      <th>surfmean_swr_flux</th>\n",
       "      <th>surfmean_lhf</th>\n",
       "      <th>surfmean_lwr_flux</th>\n",
       "      <th>surfmean_shf</th>\n",
       "      <th>dwnwrdmean_swr_flux</th>\n",
       "      <th>topmean_lwr_flux</th>\n",
       "      <th>topmean_swr_flux</th>\n",
       "      <th>vimean_moisture_div</th>\n",
       "      <th>surf_lhf</th>\n",
       "      <th>surf_shf</th>\n",
       "      <th>tot_suprcool_liqwtr</th>\n",
       "      <th>tot_wtr_vpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>239.004883</td>\n",
       "      <td>10.388416</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-15.733154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-142.741882</td>\n",
       "      <td>-31.905182</td>\n",
       "      <td>-16.616272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-151.232422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-513871.000</td>\n",
       "      <td>-59816.25</td>\n",
       "      <td>0.062388</td>\n",
       "      <td>66.840430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>353.062500</td>\n",
       "      <td>10.298082</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-17.429382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-137.203003</td>\n",
       "      <td>-35.186035</td>\n",
       "      <td>-15.780762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-144.543274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>-493928.125</td>\n",
       "      <td>-56813.50</td>\n",
       "      <td>0.043180</td>\n",
       "      <td>68.075485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>438.791016</td>\n",
       "      <td>10.022598</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-19.447388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-133.854797</td>\n",
       "      <td>-33.136688</td>\n",
       "      <td>-18.230713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-135.367188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000502</td>\n",
       "      <td>-481877.750</td>\n",
       "      <td>-65634.50</td>\n",
       "      <td>0.062830</td>\n",
       "      <td>68.349380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>537.225586</td>\n",
       "      <td>11.021526</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-19.556213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-143.641479</td>\n",
       "      <td>-33.366577</td>\n",
       "      <td>-20.231812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-140.527557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000711</td>\n",
       "      <td>-517111.250</td>\n",
       "      <td>-72834.00</td>\n",
       "      <td>0.077646</td>\n",
       "      <td>68.637733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>461.005371</td>\n",
       "      <td>10.888556</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-14.554993</td>\n",
       "      <td>62.830933</td>\n",
       "      <td>-141.330627</td>\n",
       "      <td>-34.563263</td>\n",
       "      <td>-18.625244</td>\n",
       "      <td>662.288208</td>\n",
       "      <td>-137.002502</td>\n",
       "      <td>348.938721</td>\n",
       "      <td>-0.000655</td>\n",
       "      <td>-508790.000</td>\n",
       "      <td>-67052.00</td>\n",
       "      <td>0.071162</td>\n",
       "      <td>71.056274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>845.081055</td>\n",
       "      <td>8.321689</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>0.938965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-83.707336</td>\n",
       "      <td>-33.956970</td>\n",
       "      <td>-0.830078</td>\n",
       "      <td>0.035767</td>\n",
       "      <td>-259.637756</td>\n",
       "      <td>0.022949</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-301346.000</td>\n",
       "      <td>-2991.25</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>67.968315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>959.385742</td>\n",
       "      <td>8.897865</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>0.721375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-78.474060</td>\n",
       "      <td>-32.807587</td>\n",
       "      <td>-0.852661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-239.428650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-282506.000</td>\n",
       "      <td>-3070.25</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>67.028404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1086.899414</td>\n",
       "      <td>9.283963</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-1.019653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-78.255249</td>\n",
       "      <td>-27.394897</td>\n",
       "      <td>-2.069946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-208.033783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>-281717.250</td>\n",
       "      <td>-7449.00</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>66.561859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1115.286133</td>\n",
       "      <td>7.997408</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-3.498352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.133728</td>\n",
       "      <td>-29.600922</td>\n",
       "      <td>-3.098267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-210.571594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>-238084.500</td>\n",
       "      <td>-11153.50</td>\n",
       "      <td>0.006822</td>\n",
       "      <td>67.499428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1255.678711</td>\n",
       "      <td>7.335235</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.989807</td>\n",
       "      <td>63.327209</td>\n",
       "      <td>-64.429321</td>\n",
       "      <td>-30.053406</td>\n",
       "      <td>-2.918152</td>\n",
       "      <td>442.821289</td>\n",
       "      <td>-209.759644</td>\n",
       "      <td>272.078613</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-231942.500</td>\n",
       "      <td>-10506.25</td>\n",
       "      <td>0.012928</td>\n",
       "      <td>68.823631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cape  inst_10m_wnd_gst  inst_moisture_flux  inst_ssh_flux  \\\n",
       "0    239.004883         10.388416           -0.000061     -15.733154   \n",
       "1    353.062500         10.298082           -0.000061     -17.429382   \n",
       "2    438.791016         10.022598           -0.000056     -19.447388   \n",
       "3    537.225586         11.021526           -0.000059     -19.556213   \n",
       "4    461.005371         10.888556           -0.000051     -14.554993   \n",
       "..          ...               ...                 ...            ...   \n",
       "72   845.081055          8.321689           -0.000029       0.938965   \n",
       "73   959.385742          8.897865           -0.000028       0.721375   \n",
       "74  1086.899414          9.283963           -0.000028      -1.019653   \n",
       "75  1115.286133          7.997408           -0.000026      -3.498352   \n",
       "76  1255.678711          7.335235           -0.000025      -0.989807   \n",
       "\n",
       "    surfmean_swr_flux  surfmean_lhf  surfmean_lwr_flux  surfmean_shf  \\\n",
       "0            0.000000   -142.741882         -31.905182    -16.616272   \n",
       "1            0.000000   -137.203003         -35.186035    -15.780762   \n",
       "2            0.000000   -133.854797         -33.136688    -18.230713   \n",
       "3            0.000000   -143.641479         -33.366577    -20.231812   \n",
       "4           62.830933   -141.330627         -34.563263    -18.625244   \n",
       "..                ...           ...                ...           ...   \n",
       "72           0.000000    -83.707336         -33.956970     -0.830078   \n",
       "73           0.000000    -78.474060         -32.807587     -0.852661   \n",
       "74           0.000000    -78.255249         -27.394897     -2.069946   \n",
       "75           0.000000    -66.133728         -29.600922     -3.098267   \n",
       "76          63.327209    -64.429321         -30.053406     -2.918152   \n",
       "\n",
       "    dwnwrdmean_swr_flux  topmean_lwr_flux  topmean_swr_flux  \\\n",
       "0              0.000000       -151.232422          0.000000   \n",
       "1              0.000000       -144.543274          0.000000   \n",
       "2              0.000000       -135.367188          0.000000   \n",
       "3              0.000000       -140.527557          0.000000   \n",
       "4            662.288208       -137.002502        348.938721   \n",
       "..                  ...               ...               ...   \n",
       "72             0.035767       -259.637756          0.022949   \n",
       "73             0.000000       -239.428650          0.000000   \n",
       "74             0.000000       -208.033783          0.000000   \n",
       "75             0.000000       -210.571594          0.000000   \n",
       "76           442.821289       -209.759644        272.078613   \n",
       "\n",
       "    vimean_moisture_div    surf_lhf  surf_shf  tot_suprcool_liqwtr  \\\n",
       "0             -0.000053 -513871.000 -59816.25             0.062388   \n",
       "1             -0.000081 -493928.125 -56813.50             0.043180   \n",
       "2             -0.000502 -481877.750 -65634.50             0.062830   \n",
       "3             -0.000711 -517111.250 -72834.00             0.077646   \n",
       "4             -0.000655 -508790.000 -67052.00             0.071162   \n",
       "..                  ...         ...       ...                  ...   \n",
       "72            -0.000063 -301346.000  -2991.25             0.006271   \n",
       "73            -0.000086 -282506.000  -3070.25             0.010756   \n",
       "74            -0.000189 -281717.250  -7449.00             0.006639   \n",
       "75            -0.000173 -238084.500 -11153.50             0.006822   \n",
       "76             0.000008 -231942.500 -10506.25             0.012928   \n",
       "\n",
       "    tot_wtr_vpr  \n",
       "0     66.840430  \n",
       "1     68.075485  \n",
       "2     68.349380  \n",
       "3     68.637733  \n",
       "4     71.056274  \n",
       "..          ...  \n",
       "72    67.968315  \n",
       "73    67.028404  \n",
       "74    66.561859  \n",
       "75    67.499428  \n",
       "76    68.823631  \n",
       "\n",
       "[77 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(TCrl_ts[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2f06bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readyear_automatic(year=None):\n",
    "    dm2 = xr.open_mfdataset([datapath+'/prate/prates_'+str(year)+'.nc',datapath+'/mslp/mslp_'+str(year)+'.nc',datapath+'/sst/sst_'+str(year)+'.nc'])\n",
    "    #tracklist = sorted(glob.glob('/work/FAC/FGSE/IDYST/tbeucler/default/saranya/causal/besttracks/nio/*_'+str(year)+'*'))\n",
    "    #era5_date = [str(dm2.time[i].data).split('T')[0] for i in range(len(dm2.time))]\n",
    "    #era5_hour = [str(dm2.time[i].data).split('T')[1][0:2] for i in range(len(dm2.time))]\n",
    "    return dm2#,era5_date,era5_hour\n",
    "\n",
    "dm2 = readyear_automatic(2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9672229e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d6950e8b324620998f18c3e652e5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TCpr_ts = []\n",
    "for TCname in tqdm(stormnames):\n",
    "    ###########################################################################\n",
    "    pos,indices_store,tc_irad = make_timeseries_step1(TCname=TCname,era5_date=era5_date,era5_hour=era5_hour)\n",
    "    ###########################################################################\n",
    "    mysvar = [extract_var(dataset=dm2,var=obj,indices=indices_store) for obj in (list(dm2.keys()))]\n",
    "\n",
    "    ################################################################################################\n",
    "    \n",
    "    smallsvarout = [smallarea(dm2,mysvar[i],indices_store,tc_irad) for i in (range(len(mysvar)))]\n",
    "    \n",
    "    svarname = ['mn_mslp','conv_rrate','ls_rrate','mn_conv_prate','mn_ls_prate','mn_tot_prate','sst']\n",
    "    \n",
    "    svardict = {varnameobj:varobj for (varnameobj,varobj) in zip(svarname,smallsvarout)}\n",
    "    \n",
    "    ##################################################################################################\n",
    "    #############################################################################################\n",
    "    tsdict = {}\n",
    "    for ind,obj in (enumerate(svarname)):\n",
    "        tslist = [svardict[svarname[ind]][i,...].flatten() for i in range(len(indices_store))]\n",
    "        tsdict[svarname[ind]] = [np.nanmean(obj) for obj in tslist]\n",
    "    #############################################################################################\n",
    "    TCpr_ts.append(tsdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21f2b6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "storeTCdicts = {}\n",
    "for ind in range(len(TCrl_ts)):\n",
    "    storeTCdicts[stormnames[ind]] = pd.DataFrame.from_dict(TCpr_ts[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4eb4f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind,obj in enumerate(stormnames):\n",
    "    storeTCdicts[obj].to_csv(output+'2009_presstvar_wpac_'+str(obj)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d02a093f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mn_mslp</th>\n",
       "      <th>conv_rrate</th>\n",
       "      <th>ls_rrate</th>\n",
       "      <th>mn_conv_prate</th>\n",
       "      <th>mn_ls_prate</th>\n",
       "      <th>mn_tot_prate</th>\n",
       "      <th>sst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99682.299805</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>302.673252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99669.466797</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>302.709167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99462.054688</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>302.709019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99425.217773</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>302.660847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99596.848633</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>302.355957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>99476.551758</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>301.697502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>99636.251953</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>301.652187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>99569.784180</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>301.627345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>99624.415039</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>301.602296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>99819.303711</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>301.880581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mn_mslp  conv_rrate  ls_rrate  mn_conv_prate  mn_ls_prate  \\\n",
       "0   99682.299805    0.000089  0.000121       0.000112     0.000137   \n",
       "1   99669.466797    0.000139  0.000129       0.000127     0.000128   \n",
       "2   99462.054688    0.000437  0.000130       0.000422     0.000139   \n",
       "3   99425.217773    0.000456  0.000279       0.000463     0.000322   \n",
       "4   99596.848633    0.000429  0.000199       0.000447     0.000236   \n",
       "..           ...         ...       ...            ...          ...   \n",
       "72  99476.551758    0.000021  0.000014       0.000014     0.000013   \n",
       "73  99636.251953    0.000008  0.000020       0.000009     0.000016   \n",
       "74  99569.784180    0.000055  0.000037       0.000038     0.000034   \n",
       "75  99624.415039    0.000071  0.000033       0.000045     0.000033   \n",
       "76  99819.303711    0.000020  0.000015       0.000031     0.000021   \n",
       "\n",
       "    mn_tot_prate         sst  \n",
       "0       0.000249  302.673252  \n",
       "1       0.000255  302.709167  \n",
       "2       0.000562  302.709019  \n",
       "3       0.000784  302.660847  \n",
       "4       0.000683  302.355957  \n",
       "..           ...         ...  \n",
       "72      0.000027  301.697502  \n",
       "73      0.000025  301.652187  \n",
       "74      0.000072  301.627345  \n",
       "75      0.000078  301.602296  \n",
       "76      0.000052  301.880581  \n",
       "\n",
       "[77 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(TCpr_ts[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d89c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readyear_automatic(year=None):\n",
    "    dm2=xr.open_dataset(datapath+'/slev_vars/svars_'+str(year)+'.nc') #tracklist = sorted(glob.glob('/work/FAC/FGSE/IDYST/tbeucler/default/saranya/causal/besttracks/nio/*_'+str(year)+'*'))\n",
    "    era5_date = [str(dm2.time[i].data).split('T')[0] for i in range(len(dm2.time))]\n",
    "    era5_hour = [str(dm2.time[i].data).split('T')[1][0:2] for i in range(len(dm2.time))]\n",
    "    return dm2,era5_date,era5_hour\n",
    "\n",
    "dm2,era5_date,era5_hour = readyear_automatic(2009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0348e489",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74168c9685848baab24878aad2c5c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8014df05dd7948c9b2f80ff46ae1b6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a538d422fac2428fa8d8cc9796fb19e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16ba2a200a24b958b9682b745ad61e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9008a7b9f2994528b9de8c4d0289fd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b2e80ef19f47608311c5235ad6fe63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fea3dd27ab546ac95a9e12c48bc3474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed890159f3748fe8eb4f57f2dabdb17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c6f4cabc1f4b3f90306c274a42a8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2581c6ef7184f7398cf45cad7fe1718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2fda7bff5646aeb18edb4494458c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca120bd3f4c48df940d4a25e751fd74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71abfde451914286ad4c919d3a245190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb10a36d333e43fd9bd78d5f995e73e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6c26e66755414995e78ae1f4d95116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e54cbef429d4ca99e7d14279ee8975d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b184411802418aadaf82e99d9463f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TCsl_ts = []\n",
    "for TCname in tqdm(stormnames):\n",
    "    ###########################################################################\n",
    "    pos,indices_store,tc_irad = make_timeseries_step1(TCname=TCname,era5_date=era5_date,era5_hour=era5_hour)\n",
    "    ###########################################################################\n",
    "    mysvar = [extract_var(dataset=dm2,var=obj,indices=indices_store) for obj in (list(dm2.keys()))]\n",
    "    ###########################################################################\n",
    "    ################################################################################################\n",
    "    \n",
    "    smallsvarout = [smallarea(dm2,mysvar[i],indices_store,tc_irad) for i in (range(len(mysvar)))]\n",
    "    \n",
    "    svarname = ['u10','v10','2mdewtmp','2mtmp','conv_ppt','tot_cld_ice',\\\n",
    "           'tot_cldwtr','tot_cld_rain','vi_div_cld_froz_wtr','vi_div_cld_liq_wtr','vi_div_gpot_flux',\\\n",
    "           'vi_div_ke_flux','vi_div_mass_flux','vi_div_moisture_flux','vi_div_olr_flux','vi_div_tot_enrgy_flux',\\\n",
    "           'vi_ke','vi_pe_inte','vi_pe_ie_latentenrgy','vi_temp','vi_olr','vi_tot_enrgy','vi_moisture_div']\n",
    "    svardict = {varnameobj:varobj for (varnameobj,varobj) in zip(svarname,smallsvarout)}\n",
    "    \n",
    "    ##################################################################################################\n",
    "    #############################################################################################\n",
    "    tsdict = {}\n",
    "    for ind,obj in tqdm(enumerate(svarname)):\n",
    "        tslist = [svardict[svarname[ind]][i,...].flatten() for i in range(len(indices_store))]\n",
    "        tsdict[svarname[ind]] = [np.nanmean(obj) for obj in tslist]\n",
    "    #############################################################################################\n",
    "    TCsl_ts.append(tsdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae2a8dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "storeTCdicts = {}\n",
    "for ind in range(len(TCrl_ts)):\n",
    "    storeTCdicts[stormnames[ind]] = pd.DataFrame.from_dict(TCsl_ts[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f267f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind,obj in enumerate(stormnames):\n",
    "    storeTCdicts[obj].to_csv(output+'2009_slvars_wpac_'+str(obj)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a9b3f97-39d9-46a4-9440-89713682e515",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for dm1 files functions\n",
    "def make_timeseries_step1(TCname=None,era5_date=None,era5_hour=None):\n",
    "    track=tracksDF[tracksDF['name']==TCname].reset_index()\n",
    "    lon1=track['lon'].to_numpy()\n",
    "    lat1=track['lat'].to_numpy()\n",
    "    pos = np.stack((lat1, lon1), axis=1)\n",
    "    ###########################################################################\n",
    "    indices_store = output_indices(track,era5_date,era5_hour)\n",
    "    ###########################################################################\n",
    "    tc_irad=np.empty((len(indices_store),4))\n",
    "    tc_irad[:,0] = pos[:,0]-2\n",
    "    tc_irad[:,1] = pos[:,0]+2\n",
    "    tc_irad[:,2] = pos[:,1]-2\n",
    "    tc_irad[:,3] = pos[:,1]+2\n",
    "    return pos,indices_store,tc_irad\n",
    "\n",
    "def make_timeseries_step3(dm1=None,pvarname=None,pvardict=None,indices_store=None):\n",
    "    ts_pdict = {}\n",
    "    for ind,obj in (enumerate(pvarname)):\n",
    "        pvarTS_store = []\n",
    "        for plevv in range(len(dm1.plev.data)):\n",
    "            tempvar = pvardict[pvarname[ind]][:,plevv,...]\n",
    "            tempts = [tempvar[i,...].flatten() for i in range(len(indices_store))]\n",
    "            tempTSERIES = [np.nanmean(obj) for obj in tempts]\n",
    "            pvarTS_store.append(tempTSERIES)\n",
    "        ts_pdict[pvarname[ind]] = np.asarray(pvarTS_store).transpose()\n",
    "    return ts_pdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1705d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1=xr.open_dataset(datapath+'/vor/vor_2009.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd024dec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda431e5a16f413b9f0cef804b98d7eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#For vars with 21 vertical levels vorticity humidity file##################\n",
    "TCv_ts = []\n",
    "\n",
    "for TCname in tqdm(stormnames):\n",
    "    ############################################################################\n",
    "    pos,indices_store,tc_irad = make_timeseries_step1(TCname=TCname,era5_date=era5_date,era5_hour=era5_hour)\n",
    "    ###########################################################################\n",
    "    mypvar = [extract_var(dataset=dm1,var=obj,indices=indices_store) for obj in (list(dm1.keys()))]\n",
    "    ###########################################################################\n",
    "    smallpvarout = [largearea_withpres(dm1,mypvar[i],indices_store,tc_irad) for i in (range(len(mypvar)))]    \n",
    "    pvarname = ['vor']\n",
    "    pvardict = {varnameobj:varobj for (varnameobj,varobj) in zip(pvarname,smallpvarout)}\n",
    "    #############################################################################################\n",
    "    ts_pdict = {}\n",
    "    for ind,obj in (enumerate(pvarname)):\n",
    "        pvarTS_store = []\n",
    "        for plevv in range(len(dm1.plev.data)):\n",
    "            tempvar = pvardict[pvarname[ind]][:,plevv,...]\n",
    "            tempts = [tempvar[i,...].flatten() for i in range(len(indices_store))]\n",
    "            tempTSERIES = [np.nanmean(obj) for obj in tempts]\n",
    "            pvarTS_store.append(tempTSERIES)\n",
    "        ts_pdict[pvarname[ind]] = np.asarray(pvarTS_store).transpose()\n",
    "    #############################################################################################\n",
    "    #############################################################################################\n",
    "    TCv_ts.append(ts_pdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66ac6596",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1=xr.open_dataset(datapath+'/rhum/rhum_2009.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e711b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82eb5be5abd4d3ba7780f7b424080a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TCrh_ts = []\n",
    "\n",
    "for TCname in tqdm(stormnames):\n",
    "    ############################################################################\n",
    "    pos,indices_store,tc_irad = make_timeseries_step1(TCname=TCname,era5_date=era5_date,era5_hour=era5_hour)\n",
    "    ###########################################################################\n",
    "    mypvar = [extract_var(dataset=dm1,var=obj,indices=indices_store) for obj in (list(dm1.keys()))]\n",
    "    ###########################################################################\n",
    "    smallpvarout = [largearea_withpres(dm1,mypvar[i],indices_store,tc_irad) for i in (range(len(mypvar)))]    \n",
    "    pvarname = ['rhum']\n",
    "    pvardict = {varnameobj:varobj for (varnameobj,varobj) in zip(pvarname,smallpvarout)}\n",
    "    #############################################################################################\n",
    "    ts_pdict = {}\n",
    "    for ind,obj in (enumerate(pvarname)):\n",
    "        pvarTS_store = []\n",
    "        for plevv in range(len(dm1.plev.data)):\n",
    "            tempvar = pvardict[pvarname[ind]][:,plevv,...]\n",
    "            tempts = [tempvar[i,...].flatten() for i in range(len(indices_store))]\n",
    "            tempTSERIES = [np.nanmean(obj) for obj in tempts]\n",
    "            pvarTS_store.append(tempTSERIES)\n",
    "        ts_pdict[pvarname[ind]] = np.asarray(pvarTS_store).transpose()\n",
    "    #############################################################################################\n",
    "    #############################################################################################\n",
    "    TCrh_ts.append(ts_pdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a16f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1=xr.open_dataset(datapath+'/pvor/pvor_2009.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21d1a3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22cd4d48b8a44e39bdc00c22fbcaeb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#potential vorticity\n",
    "TCp2_ts = []\n",
    "\n",
    "for TCname in tqdm(stormnames):\n",
    "    ############################################################################\n",
    "    pos,indices_store,tc_irad = make_timeseries_step1(TCname=TCname,era5_date=era5_date,era5_hour=era5_hour)\n",
    "    ###########################################################################\n",
    "    mypvar = [extract_var(dataset=dm1,var=obj,indices=indices_store) for obj in (list(dm1.keys()))]\n",
    "    ###########################################################################\n",
    "    smallpvarout = [largearea_withpres(dm1,mypvar[i],indices_store,tc_irad) for i in (range(len(mypvar)))]    \n",
    "    pvarname = ['pvor']\n",
    "    pvardict = {varnameobj:varobj for (varnameobj,varobj) in zip(pvarname,smallpvarout)}\n",
    "    #############################################################################################\n",
    "    ts_pdict = {}\n",
    "    for ind,obj in (enumerate(pvarname)):\n",
    "        pvarTS_store = []\n",
    "        for plevv in range(len(dm1.plev.data)):\n",
    "            tempvar = pvardict[pvarname[ind]][:,plevv,...]\n",
    "            tempts = [tempvar[i,...].flatten() for i in range(len(indices_store))]\n",
    "            tempTSERIES = [np.nanmean(obj) for obj in tempts]\n",
    "            pvarTS_store.append(tempTSERIES)\n",
    "        ts_pdict[pvarname[ind]] = np.asarray(pvarTS_store).transpose()\n",
    "    #############################################################################################\n",
    "    TCp2_ts.append(ts_pdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67bc18a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1=xr.open_dataset(datapath+'/div/div_2009.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca17b8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48ad6d6cc084cef936565fa227bb070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#divergence\n",
    "TCd_ts = []\n",
    "for TCname in tqdm(stormnames):\n",
    "    ############################################################################\n",
    "    pos,indices_store,tc_irad = make_timeseries_step1(TCname=TCname,era5_date=era5_date,era5_hour=era5_hour)\n",
    "    ###########################################################################\n",
    "    mypvar = [extract_var(dataset=dm1,var=obj,indices=indices_store) for obj in (list(dm1.keys()))]\n",
    "    ###########################################################################\n",
    "    smallpvarout = [largearea_withpres(dm1,mypvar[i],indices_store,tc_irad) for i in (range(len(mypvar)))]    \n",
    "    pvarname = ['div']\n",
    "    pvardict = {varnameobj:varobj for (varnameobj,varobj) in zip(pvarname,smallpvarout)}\n",
    "    #############################################################################################\n",
    "    ts_pdict = {}\n",
    "    for ind,obj in (enumerate(pvarname)):\n",
    "        pvarTS_store = []\n",
    "        for plevv in range(len(dm1.plev.data)):\n",
    "            tempvar = pvardict[pvarname[ind]][:,plevv,...]\n",
    "            tempts = [tempvar[i,...].flatten() for i in range(len(indices_store))]\n",
    "            tempTSERIES = [np.nanmean(obj) for obj in tempts]\n",
    "            pvarTS_store.append(tempTSERIES)\n",
    "        ts_pdict[pvarname[ind]] = np.asarray(pvarTS_store).transpose()\n",
    "\n",
    "    #############################################################################################\n",
    "    TCd_ts.append(ts_pdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1eead177",
   "metadata": {},
   "outputs": [],
   "source": [
    "pilv=[str(int(obj)) for obj in dm1.plev.data/100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "542a11af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['50',\n",
       " '100',\n",
       " '200',\n",
       " '250',\n",
       " '300',\n",
       " '400',\n",
       " '500',\n",
       " '600',\n",
       " '700',\n",
       " '800',\n",
       " '850',\n",
       " '925',\n",
       " '1000']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pilv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ddf6a7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1=xr.open_dataset(datapath+'/gpot/gpot_2009.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c2abd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642fed72609d491eb19edcd072675aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#geopotential\n",
    "TCgp_ts = []\n",
    "for TCname in tqdm(stormnames):\n",
    "    ############################################################################\n",
    "    pos,indices_store,tc_irad = make_timeseries_step1(TCname=TCname,era5_date=era5_date,era5_hour=era5_hour)\n",
    "    ###########################################################################\n",
    "    mypvar = [extract_var(dataset=dm1,var=obj,indices=indices_store) for obj in (list(dm1.keys()))]\n",
    "    ###########################################################################\n",
    "    smallpvarout = [largearea_withpres(dm1,mypvar[i],indices_store,tc_irad) for i in (range(len(mypvar)))]    \n",
    "    pvarname = ['gpot']\n",
    "    pvardict = {varnameobj:varobj for (varnameobj,varobj) in zip(pvarname,smallpvarout)}\n",
    "    #############################################################################################\n",
    "    ts_pdict = {}\n",
    "    for ind,obj in (enumerate(pvarname)):\n",
    "        pvarTS_store = []\n",
    "        for plevv in range(len(dm1.plev.data)):\n",
    "            tempvar = pvardict[pvarname[ind]][:,plevv,...]\n",
    "            tempts = [tempvar[i,...].flatten() for i in range(len(indices_store))]\n",
    "            tempTSERIES = [np.nanmean(obj) for obj in tempts]\n",
    "            pvarTS_store.append(tempTSERIES)\n",
    "        ts_pdict[pvarname[ind]] = np.asarray(pvarTS_store).transpose()\n",
    "    #############################################################################################\n",
    "    TCgp_ts.append(ts_pdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a70e3007",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1=xr.open_dataset(datapath+'/tlevs/tlevs_2009.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff3da54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f21a08dcc68417f867696a472bff4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#temperature levels\n",
    "TCtl_ts = []\n",
    "for TCname in tqdm(stormnames):\n",
    "    ############################################################################\n",
    "    pos,indices_store,tc_irad = make_timeseries_step1(TCname=TCname,era5_date=era5_date,era5_hour=era5_hour)\n",
    "    ###########################################################################\n",
    "    mypvar = [extract_var(dataset=dm1,var=obj,indices=indices_store) for obj in (list(dm1.keys()))]\n",
    "    ###########################################################################\n",
    "    smallpvarout = [largearea_withpres(dm1,mypvar[i],indices_store,tc_irad) for i in (range(len(mypvar)))]    \n",
    "    pvarname = ['temp']\n",
    "    pvardict = {varnameobj:varobj for (varnameobj,varobj) in zip(pvarname,smallpvarout)}\n",
    "    #############################################################################################\n",
    "    ts_pdict = {}\n",
    "    for ind,obj in (enumerate(pvarname)):\n",
    "        pvarTS_store = []\n",
    "        for plevv in range(len(dm1.plev.data)):\n",
    "            tempvar = pvardict[pvarname[ind]][:,plevv,...]\n",
    "            tempts = [tempvar[i,...].flatten() for i in range(len(indices_store))]\n",
    "            tempTSERIES = [np.nanmean(obj) for obj in tempts]\n",
    "            pvarTS_store.append(tempTSERIES)\n",
    "        ts_pdict[pvarname[ind]] = np.asarray(pvarTS_store).transpose()\n",
    "    #############################################################################################\n",
    "    TCtl_ts.append(ts_pdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be115071",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm1=xr.open_dataset(datapath+'/vvel/w_wnd_2009.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05fe0398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9350e198b749ddafe1ba22140d9ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Vertical velocity\n",
    "TCvv_ts = []\n",
    "for TCname in tqdm(stormnames):\n",
    "    ###########################################################################\n",
    "    pos,indices_store,tc_irad = make_timeseries_step1(TCname=TCname,era5_date=era5_date,era5_hour=era5_hour)\n",
    "    ###########################################################################\n",
    "    mypvar = [extract_var(dataset=dm1,var=obj,indices=indices_store) for obj in (list(dm1.keys()))]\n",
    "    ###########################################################################\n",
    "    smallpvarout = [largearea_withpres(dm1,mypvar[i],indices_store,tc_irad) for i in (range(len(mypvar)))]    \n",
    "    pvarname = ['vvel']\n",
    "    pvardict = {varnameobj:varobj for (varnameobj,varobj) in zip(pvarname,smallpvarout)}\n",
    "    \n",
    "    ts_pdict = make_timeseries_step3(dm1=dm1,pvarname=pvarname,pvardict=pvardict,indices_store=indices_store)\n",
    "    #############################################################################################\n",
    "    TCvv_ts.append(ts_pdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6be9f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "plv = [str(int(obj)) for obj in dm1.plev.data/100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83814dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx=xr.open_dataset(datapath+'/tlevs/tlevs_2009.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9418396",
   "metadata": {},
   "outputs": [],
   "source": [
    "plev=[str(int(obj)) for obj in dx.plev.data/100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bdaca644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '20',\n",
       " '30',\n",
       " '50',\n",
       " '70',\n",
       " '100',\n",
       " '150',\n",
       " '200',\n",
       " '250',\n",
       " '300',\n",
       " '400',\n",
       " '500',\n",
       " '600',\n",
       " '700',\n",
       " '850',\n",
       " '925',\n",
       " '975',\n",
       " '1000']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ade34e5-ebe3-4f6d-946f-a386724ec39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 13, 21, (101, 21))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plv),len(pilv),len(plev),TCgp_ts[0]['gpot'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0be51602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pandadict(divdict=None,vordict=None,rhdict=None,gpotdict=None,tempdict=None,vveldict=None,divlv=pilv,vorlv=plev,\\\n",
    "                     rhlev=plev,gpotlv=plev,templv=plev,vvellv=plv):\n",
    "    tempdivdict = {'div_'+divlv[i]:divdict['div'][:,i] for i in range(divdict['div'].shape[1])}\n",
    "    tempvordict = {'vor_'+vorlv[i]:vordict['vor'][:,i] for i in range(vordict['vor'].shape[1])}\n",
    "    temprhdict = {'rh_'+rhlev[i]:rhdict['rhum'][:,i] for i in range(rhdict['rhum'].shape[1])}\n",
    "    tempgpotdict = {'gpot_'+gpotlv[i]:gpotdict['gpot'][:,i] for i in range(gpotdict['gpot'].shape[1])}\n",
    "    temptempdict = {'temp_'+templv[i]:tempdict['temp'][:,i] for i in range(tempdict['temp'].shape[1])}\n",
    "    tempvveldict = {'vvel_'+vvellv[i]:vveldict['vvel'][:,i] for i in range(vveldict['vvel'].shape[1])}   \n",
    "    dict1 = {**tempdivdict,**tempvordict} # change this later\n",
    "    dict2 = {**temprhdict,**tempgpotdict}\n",
    "    dict3 = {**temptempdict,**tempvveldict}\n",
    "    combine1={**dict1,**dict2} # change this later\n",
    "    alldict = {**combine1,**dict3} # change this later\n",
    "    #alldict= {**dict2,**dict3}\n",
    "    return alldict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78d9b4e2-268d-4697-953e-acec28a63a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storeTCdicts = {}\n",
    "for ind in range(len(TCp2_ts)):\n",
    "    storeTCdicts[stormnames[ind]] = pd.DataFrame.from_dict(create_pandadict(divdict=TCd_ts[ind],vordict=TCv_ts[ind],\\\n",
    "                                                                            rhdict=TCrh_ts[ind],gpotdict=TCgp_ts[ind],\\\n",
    "                                                                            tempdict=TCtl_ts[ind],vveldict=TCvv_ts[ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a567a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind,obj in enumerate(stormnames):\n",
    "    storeTCdicts[obj].to_csv(output+'2009_innerlevs_wpac_'+str(obj)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd52c765-3ab0-4c27-8284-a5e0803681e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d86fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550e360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae5ebaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "23eae186",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'vort'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [90]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#TCp_ts[0]['vort']stands for the vorticity of the first storm and vort again contains 21 pressure levels.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#preslv = [str(int(obj)) for obj in dm1.plev.data/100]\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m tempvortdict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvort_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mplev[i]:TCv_ts[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvort\u001b[39m\u001b[38;5;124m'\u001b[39m][:,i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m21\u001b[39m)} \u001b[38;5;66;03m# add this later\u001b[39;00m\n\u001b[1;32m      5\u001b[0m temprhumdict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrhum_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mplev[i]:TCv_ts[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrhum\u001b[39m\u001b[38;5;124m'\u001b[39m][:,i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m21\u001b[39m)} \u001b[38;5;66;03m# add this later\u001b[39;00m\n\u001b[1;32m      6\u001b[0m temppvordict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpvor_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mpreslv[i]:TCp2_ts[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpvor\u001b[39m\u001b[38;5;124m'\u001b[39m][:,i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m18\u001b[39m)}\n",
      "Input \u001b[0;32mIn [90]\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#TCp_ts[0]['vort']stands for the vorticity of the first storm and vort again contains 21 pressure levels.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#preslv = [str(int(obj)) for obj in dm1.plev.data/100]\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m tempvortdict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvort_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mplev[i]:\u001b[43mTCv_ts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[:,i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m21\u001b[39m)} \u001b[38;5;66;03m# add this later\u001b[39;00m\n\u001b[1;32m      5\u001b[0m temprhumdict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrhum_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mplev[i]:TCv_ts[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrhum\u001b[39m\u001b[38;5;124m'\u001b[39m][:,i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m21\u001b[39m)} \u001b[38;5;66;03m# add this later\u001b[39;00m\n\u001b[1;32m      6\u001b[0m temppvordict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpvor_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mpreslv[i]:TCp2_ts[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpvor\u001b[39m\u001b[38;5;124m'\u001b[39m][:,i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m18\u001b[39m)}\n",
      "\u001b[0;31mKeyError\u001b[0m: 'vort'"
     ]
    }
   ],
   "source": [
    "#TCp_ts[0]['vort']stands for the vorticity of the first storm and vort again contains 21 pressure levels.\n",
    "#preslv = [str(int(obj)) for obj in dm1.plev.data/100]\n",
    "\n",
    "tempvortdict = {'vort_'+plev[i]:TCv_ts[0]['vort'][:,i] for i in range(21)} # add this later\n",
    "temprhumdict = {'rhum_'+plev[i]:TCv_ts[0]['rhum'][:,i] for i in range(21)} # add this later\n",
    "temppvordict = {'pvor_'+preslv[i]:TCp2_ts[0]['pvor'][:,i] for i in range(18)}\n",
    "tempgpotdict = {'gpot_'+plv[i]:TCgp_ts[0]['gpot'][:,i] for i in range(20)}\n",
    "temptempdict = {'temp_'+plev[i]:TCtl_ts[0]['temp'][:,i] for i in range(21)}\n",
    "tempvveldict = {'vvel_'+preslv[i]:TCvv_ts[0]['vvel'][:,i] for i in range(18)}\n",
    "dict1 = {**tempvortdict,**temprhumdict}\n",
    "dict2 = {**temppvordict,**tempgpotdict}\n",
    "dict3 = {**temptempdict,**tempvveldict}\n",
    "combine1={**dict1,**dict2}\n",
    "alldict = {**combine1,**dict3}\n",
    "#pts2020_amphan=pd.DataFrame.from_dict(plvdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a18d688",
   "metadata": {},
   "outputs": [],
   "source": [
    "plev_2021=pd.DataFrame.from_dict(alldict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6ce2b27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_gul21=pd.concat([div_21,eqt_21,sl2021,rad2021,pr2021,plev_2021], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2ddc557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>div_50</th>\n",
       "      <th>div_100</th>\n",
       "      <th>div_200</th>\n",
       "      <th>div_250</th>\n",
       "      <th>div_300</th>\n",
       "      <th>div_400</th>\n",
       "      <th>div_500</th>\n",
       "      <th>div_600</th>\n",
       "      <th>div_700</th>\n",
       "      <th>div_800</th>\n",
       "      <th>...</th>\n",
       "      <th>vvel_250</th>\n",
       "      <th>vvel_300</th>\n",
       "      <th>vvel_400</th>\n",
       "      <th>vvel_500</th>\n",
       "      <th>vvel_600</th>\n",
       "      <th>vvel_700</th>\n",
       "      <th>vvel_850</th>\n",
       "      <th>vvel_925</th>\n",
       "      <th>vvel_975</th>\n",
       "      <th>vvel_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.470139e-05</td>\n",
       "      <td>-2.004806e-05</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.717859e-05</td>\n",
       "      <td>1.207291e-05</td>\n",
       "      <td>8.906121e-06</td>\n",
       "      <td>-1.034816e-06</td>\n",
       "      <td>7.125200e-07</td>\n",
       "      <td>-3.069406e-06</td>\n",
       "      <td>-4.832400e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179325</td>\n",
       "      <td>-0.259124</td>\n",
       "      <td>-0.360181</td>\n",
       "      <td>-0.382818</td>\n",
       "      <td>-0.385455</td>\n",
       "      <td>-0.363965</td>\n",
       "      <td>-0.295342</td>\n",
       "      <td>-0.182406</td>\n",
       "      <td>-0.074252</td>\n",
       "      <td>-0.017509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.488989e-05</td>\n",
       "      <td>-5.881069e-06</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1.001521e-05</td>\n",
       "      <td>7.239578e-06</td>\n",
       "      <td>-2.546585e-06</td>\n",
       "      <td>2.435117e-06</td>\n",
       "      <td>-5.611917e-06</td>\n",
       "      <td>-5.518668e-07</td>\n",
       "      <td>-1.899782e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.201773</td>\n",
       "      <td>-0.238356</td>\n",
       "      <td>-0.244928</td>\n",
       "      <td>-0.229633</td>\n",
       "      <td>-0.239007</td>\n",
       "      <td>-0.181803</td>\n",
       "      <td>-0.169252</td>\n",
       "      <td>-0.119534</td>\n",
       "      <td>-0.056306</td>\n",
       "      <td>-0.018626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.774957e-06</td>\n",
       "      <td>-1.693203e-06</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>3.927038e-06</td>\n",
       "      <td>-8.301693e-06</td>\n",
       "      <td>-1.514552e-05</td>\n",
       "      <td>-1.117820e-06</td>\n",
       "      <td>2.739776e-06</td>\n",
       "      <td>-5.193695e-06</td>\n",
       "      <td>6.410002e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151920</td>\n",
       "      <td>-0.137368</td>\n",
       "      <td>-0.016568</td>\n",
       "      <td>0.070683</td>\n",
       "      <td>0.044295</td>\n",
       "      <td>0.076153</td>\n",
       "      <td>0.026839</td>\n",
       "      <td>-0.005580</td>\n",
       "      <td>0.007360</td>\n",
       "      <td>0.018210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.540430e-06</td>\n",
       "      <td>5.546259e-06</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>9.460666e-06</td>\n",
       "      <td>-8.159375e-06</td>\n",
       "      <td>-6.259594e-06</td>\n",
       "      <td>-4.779082e-06</td>\n",
       "      <td>1.751061e-06</td>\n",
       "      <td>-1.289300e-07</td>\n",
       "      <td>5.345559e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156391</td>\n",
       "      <td>-0.158884</td>\n",
       "      <td>-0.086677</td>\n",
       "      <td>-0.047792</td>\n",
       "      <td>-0.028524</td>\n",
       "      <td>-0.031328</td>\n",
       "      <td>-0.089968</td>\n",
       "      <td>-0.073317</td>\n",
       "      <td>-0.020160</td>\n",
       "      <td>0.013664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.277926e-05</td>\n",
       "      <td>2.870103e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>5.408539e-06</td>\n",
       "      <td>-6.243528e-06</td>\n",
       "      <td>6.831135e-06</td>\n",
       "      <td>1.678709e-07</td>\n",
       "      <td>1.325330e-06</td>\n",
       "      <td>7.220078e-07</td>\n",
       "      <td>1.140637e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165562</td>\n",
       "      <td>-0.165935</td>\n",
       "      <td>-0.179049</td>\n",
       "      <td>-0.213646</td>\n",
       "      <td>-0.220336</td>\n",
       "      <td>-0.232739</td>\n",
       "      <td>-0.245793</td>\n",
       "      <td>-0.176871</td>\n",
       "      <td>-0.078091</td>\n",
       "      <td>-0.024020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-3.872090e-06</td>\n",
       "      <td>-4.878500e-06</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>4.795962e-06</td>\n",
       "      <td>8.417992e-07</td>\n",
       "      <td>4.533329e-06</td>\n",
       "      <td>-4.068715e-07</td>\n",
       "      <td>-1.222652e-05</td>\n",
       "      <td>-2.529082e-05</td>\n",
       "      <td>-1.379685e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332974</td>\n",
       "      <td>-0.345632</td>\n",
       "      <td>-0.376871</td>\n",
       "      <td>-0.417450</td>\n",
       "      <td>-0.363439</td>\n",
       "      <td>-0.170226</td>\n",
       "      <td>0.073287</td>\n",
       "      <td>0.059968</td>\n",
       "      <td>0.022831</td>\n",
       "      <td>0.031646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1.046498e-05</td>\n",
       "      <td>-6.112386e-07</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>8.770730e-07</td>\n",
       "      <td>-3.539375e-06</td>\n",
       "      <td>3.801601e-06</td>\n",
       "      <td>-2.524524e-06</td>\n",
       "      <td>-1.678348e-05</td>\n",
       "      <td>-3.209530e-05</td>\n",
       "      <td>-1.239870e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.463555</td>\n",
       "      <td>-0.455450</td>\n",
       "      <td>-0.437432</td>\n",
       "      <td>-0.476495</td>\n",
       "      <td>-0.402014</td>\n",
       "      <td>-0.120978</td>\n",
       "      <td>0.123721</td>\n",
       "      <td>0.091201</td>\n",
       "      <td>0.027067</td>\n",
       "      <td>0.026226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-3.096648e-07</td>\n",
       "      <td>-5.463196e-06</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>1.734338e-05</td>\n",
       "      <td>-3.813999e-06</td>\n",
       "      <td>3.948808e-06</td>\n",
       "      <td>-9.298674e-06</td>\n",
       "      <td>-3.250362e-05</td>\n",
       "      <td>-2.863479e-05</td>\n",
       "      <td>-9.745010e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.633262</td>\n",
       "      <td>-0.663047</td>\n",
       "      <td>-0.619403</td>\n",
       "      <td>-0.636304</td>\n",
       "      <td>-0.430235</td>\n",
       "      <td>-0.075319</td>\n",
       "      <td>0.126537</td>\n",
       "      <td>0.079193</td>\n",
       "      <td>0.016556</td>\n",
       "      <td>0.001574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>3.144261e-06</td>\n",
       "      <td>-1.742784e-05</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>1.299020e-05</td>\n",
       "      <td>-1.123449e-05</td>\n",
       "      <td>-4.185305e-06</td>\n",
       "      <td>-1.553120e-05</td>\n",
       "      <td>-2.349971e-05</td>\n",
       "      <td>-1.744000e-05</td>\n",
       "      <td>4.005851e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.388316</td>\n",
       "      <td>-0.391463</td>\n",
       "      <td>-0.256868</td>\n",
       "      <td>-0.165840</td>\n",
       "      <td>0.070560</td>\n",
       "      <td>0.315451</td>\n",
       "      <td>0.356788</td>\n",
       "      <td>0.221411</td>\n",
       "      <td>0.084055</td>\n",
       "      <td>0.041359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-3.384193e-07</td>\n",
       "      <td>-8.378294e-06</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>6.530317e-06</td>\n",
       "      <td>-8.087722e-06</td>\n",
       "      <td>7.246272e-07</td>\n",
       "      <td>-1.445104e-05</td>\n",
       "      <td>-2.099917e-05</td>\n",
       "      <td>-1.772260e-05</td>\n",
       "      <td>5.969312e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188751</td>\n",
       "      <td>-0.189928</td>\n",
       "      <td>-0.124838</td>\n",
       "      <td>-0.054407</td>\n",
       "      <td>0.154492</td>\n",
       "      <td>0.347481</td>\n",
       "      <td>0.344084</td>\n",
       "      <td>0.203439</td>\n",
       "      <td>0.065261</td>\n",
       "      <td>0.019004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          div_50       div_100   div_200       div_250       div_300  \\\n",
       "0  -1.470139e-05 -2.004806e-05  0.000018  1.717859e-05  1.207291e-05   \n",
       "1  -2.488989e-05 -5.881069e-06  0.000022  1.001521e-05  7.239578e-06   \n",
       "2  -5.774957e-06 -1.693203e-06  0.000016  3.927038e-06 -8.301693e-06   \n",
       "3  -4.540430e-06  5.546259e-06  0.000010  9.460666e-06 -8.159375e-06   \n",
       "4   1.277926e-05  2.870103e-06  0.000009  5.408539e-06 -6.243528e-06   \n",
       "..           ...           ...       ...           ...           ...   \n",
       "76 -3.872090e-06 -4.878500e-06  0.000037  4.795962e-06  8.417992e-07   \n",
       "77  1.046498e-05 -6.112386e-07  0.000041  8.770730e-07 -3.539375e-06   \n",
       "78 -3.096648e-07 -5.463196e-06  0.000052  1.734338e-05 -3.813999e-06   \n",
       "79  3.144261e-06 -1.742784e-05  0.000044  1.299020e-05 -1.123449e-05   \n",
       "80 -3.384193e-07 -8.378294e-06  0.000032  6.530317e-06 -8.087722e-06   \n",
       "\n",
       "         div_400       div_500       div_600       div_700       div_800  ...  \\\n",
       "0   8.906121e-06 -1.034816e-06  7.125200e-07 -3.069406e-06 -4.832400e-06  ...   \n",
       "1  -2.546585e-06  2.435117e-06 -5.611917e-06 -5.518668e-07 -1.899782e-06  ...   \n",
       "2  -1.514552e-05 -1.117820e-06  2.739776e-06 -5.193695e-06  6.410002e-06  ...   \n",
       "3  -6.259594e-06 -4.779082e-06  1.751061e-06 -1.289300e-07  5.345559e-06  ...   \n",
       "4   6.831135e-06  1.678709e-07  1.325330e-06  7.220078e-07  1.140637e-06  ...   \n",
       "..           ...           ...           ...           ...           ...  ...   \n",
       "76  4.533329e-06 -4.068715e-07 -1.222652e-05 -2.529082e-05 -1.379685e-05  ...   \n",
       "77  3.801601e-06 -2.524524e-06 -1.678348e-05 -3.209530e-05 -1.239870e-05  ...   \n",
       "78  3.948808e-06 -9.298674e-06 -3.250362e-05 -2.863479e-05 -9.745010e-06  ...   \n",
       "79 -4.185305e-06 -1.553120e-05 -2.349971e-05 -1.744000e-05  4.005851e-07  ...   \n",
       "80  7.246272e-07 -1.445104e-05 -2.099917e-05 -1.772260e-05  5.969312e-06  ...   \n",
       "\n",
       "    vvel_250  vvel_300  vvel_400  vvel_500  vvel_600  vvel_700  vvel_850  \\\n",
       "0  -0.179325 -0.259124 -0.360181 -0.382818 -0.385455 -0.363965 -0.295342   \n",
       "1  -0.201773 -0.238356 -0.244928 -0.229633 -0.239007 -0.181803 -0.169252   \n",
       "2  -0.151920 -0.137368 -0.016568  0.070683  0.044295  0.076153  0.026839   \n",
       "3  -0.156391 -0.158884 -0.086677 -0.047792 -0.028524 -0.031328 -0.089968   \n",
       "4  -0.165562 -0.165935 -0.179049 -0.213646 -0.220336 -0.232739 -0.245793   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "76 -0.332974 -0.345632 -0.376871 -0.417450 -0.363439 -0.170226  0.073287   \n",
       "77 -0.463555 -0.455450 -0.437432 -0.476495 -0.402014 -0.120978  0.123721   \n",
       "78 -0.633262 -0.663047 -0.619403 -0.636304 -0.430235 -0.075319  0.126537   \n",
       "79 -0.388316 -0.391463 -0.256868 -0.165840  0.070560  0.315451  0.356788   \n",
       "80 -0.188751 -0.189928 -0.124838 -0.054407  0.154492  0.347481  0.344084   \n",
       "\n",
       "    vvel_925  vvel_975  vvel_1000  \n",
       "0  -0.182406 -0.074252  -0.017509  \n",
       "1  -0.119534 -0.056306  -0.018626  \n",
       "2  -0.005580  0.007360   0.018210  \n",
       "3  -0.073317 -0.020160   0.013664  \n",
       "4  -0.176871 -0.078091  -0.024020  \n",
       "..       ...       ...        ...  \n",
       "76  0.059968  0.022831   0.031646  \n",
       "77  0.091201  0.027067   0.026226  \n",
       "78  0.079193  0.016556   0.001574  \n",
       "79  0.221411  0.084055   0.041359  \n",
       "80  0.203439  0.065261   0.019004  \n",
       "\n",
       "[81 rows x 190 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_gul21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1b105ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_gul21.to_csv(output+'inner/inner_nio_20210924.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a03cbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f636a33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
